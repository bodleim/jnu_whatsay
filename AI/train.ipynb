{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data load, preprocessing\n",
    "data = pd.read_csv('./dataset.txt', sep = \",\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "texts = data['text_column']\n",
    "labels = data['label_column']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"amount of datas : \" + str(texts.count()))\n",
    "\n",
    "amount_of_food = 0\n",
    "amount_of_it = 0\n",
    "amount_of_school = 0\n",
    "amount_of_sports = 0\n",
    "\n",
    "for i in labels:\n",
    "    if i == 0:\n",
    "        amount_of_food += 1\n",
    "    elif i == 1:\n",
    "        amount_of_it += 1\n",
    "    elif i == 2:\n",
    "        amount_of_school += 1\n",
    "    elif i == 3:\n",
    "        amount_of_sports += 1\n",
    "\n",
    "print(\"food_data : \" + str(amount_of_food) + \"\\nit_data : \" + str(amount_of_it) + \"\\nschool_data : \" + str(amount_of_school) + \"\\nsports_data : \" + str(amount_of_sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "morpheme_sep = []\n",
    "\n",
    "twt = Okt()\n",
    "\n",
    "for i, j in enumerate(texts):\n",
    "    tagging = twt.pos(texts[i])\n",
    "    #print(str(tagging) + \"\\n\")\n",
    "\n",
    "    for k, h in tagging:\n",
    "        morpheme_sep.append(k)\n",
    "\n",
    "    stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들','의', '있', '되', '수', '보', '주', '등', '한'])\n",
    "    clean_data = [token for token in morpheme_sep if not token in stop_words]\n",
    "    \n",
    "\n",
    "print(\"not apply stop_words : \" + str(morpheme_sep))\n",
    "print(\"apply stop_words : \" + str(clean_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 텍스트 형태소 분석\n",
    "okt = Okt()\n",
    "texts = texts.apply(lambda x: ' '.join(okt.morphs(x)))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "X = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(X, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[560])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NaN 또는 무한대 값을 가지는 인덱스 검사\n",
    "nan_indices = np.where(np.isnan(labels))\n",
    "inf_indices = np.where(np.isinf(labels))\n",
    "\n",
    "print(\"NaN 값을 가지는 인덱스:\", nan_indices)\n",
    "print(\"무한대 값을 가지는 인덱스:\", inf_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass label prepare\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "mean_value = labels.mean()\n",
    "labels.fillna(mean_value, inplace=True)\n",
    "\n",
    "# labels 배열을 정수로 변환\n",
    "labels = labels.astype(int)\n",
    "y = to_categorical(labels, num_classes=4)  # amount of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data divising\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model structure\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=500, output_dim=64, input_length=50))\n",
    "model.add(LSTM(4))\n",
    "model.add(Dense(4, activation='softmax'))  # print softmax of 4 class\n",
    "\n",
    "# compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "from keras.callbacks import EarlyStopping \n",
    "early_stopping = EarlyStopping(patience = 2) # protect overfitting\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=100, validation_split=0.2, verbose=1, callbacks = [early_stopping])\n",
    "print(history.history)\n",
    "\n",
    "# training visualizing (accuracy)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#training visualizing (loss)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# model save\n",
    "model.save('./recog_situation_model.h5')\n",
    "print(\"학습된 모델이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
